{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdmelo/atlantis-example/blob/master/2-4-11-AssignmentQuestion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktqTCGHJw-ws"
      },
      "source": [
        "# Bean Disease Classifier\n",
        "For this assignment you'll take what you've learned so far and build a classifier for bean disease. You'll be provided with training and validation data based on 224x224 pixel color images taken of bean plants in Uganda. These images show healthy bean leaves as well as 2 types of common disease: bean rust and angular leaf spots. Your job will be to build a neural network that can tell the difference between the healthy and diseased leaves.\n",
        "\n",
        "We start by setting up the problem for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wmnkg6vGbX1t",
        "outputId": "ee4f226d-b711-4bb1-ef37-38c406ae9594",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "# Do not change this code\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lRV-f1DSwwiC",
        "outputId": "5dab69e4-837a-436e-8c42-5576e6c932a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Collecting gdown\n",
            "  Downloading gdown-5.1.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.7.3\n",
            "    Uninstalling gdown-4.7.3:\n",
            "      Successfully uninstalled gdown-4.7.3\n",
            "Successfully installed gdown-5.1.0\n"
          ]
        }
      ],
      "source": [
        "# Do not change this code\n",
        "!pip install --upgrade --no-cache-dir gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "njf4YhwFb6hW",
        "outputId": "55e45fb0-ad1f-4d63-87c9-3475a179d16a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://storage.googleapis.com/learning-datasets/beans/train.zip\n",
            "To: /tmp/train.zip\n",
            "100% 144M/144M [00:05<00:00, 24.3MB/s]\n",
            "Downloading...\n",
            "From: https://storage.googleapis.com/learning-datasets/beans/validation.zip\n",
            "To: /tmp/validation.zip\n",
            "100% 18.5M/18.5M [00:00<00:00, 36.8MB/s]\n",
            "Downloading...\n",
            "From: https://storage.googleapis.com/learning-datasets/beans/test.zip\n",
            "To: /tmp/test.zip\n",
            "100% 17.7M/17.7M [00:00<00:00, 38.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Do not change this code\n",
        "!gdown \"https://storage.googleapis.com/learning-datasets/beans/train.zip\" -O /tmp/train.zip\n",
        "!gdown \"https://storage.googleapis.com/learning-datasets/beans/validation.zip\" -O /tmp/validation.zip\n",
        "!gdown \"https://storage.googleapis.com/learning-datasets/beans/test.zip\" -O /tmp/test.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KscpTrSWcK1T"
      },
      "outputs": [],
      "source": [
        "# Do not change this code\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/train.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "local_zip = '/tmp/validation.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "local_zip = '/tmp/test.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/test')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R0WEYIitNwI"
      },
      "source": [
        "Now you need to define a generator to process the data we have loaded in Colab so that our model can use it for training. As we showed in the previous video you'll first have to define an ```ImageDataGenerator``` and then flow the data into it.\n",
        "\n",
        "*A hint: You don't want abnormal data!*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jCiSd248caB4",
        "outputId": "0859aa19-e36b-4bbb-863b-c8ff50fcd5a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1034 images belonging to 3 classes.\n",
            "Found 133 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "TRAIN_DIRECTORY_LOCATION = '/tmp/train'\n",
        "VAL_DIRECTORY_LOCATION = '/tmp/validation'\n",
        "TARGET_SIZE = (224,224)\n",
        "CLASS_MODE = 'categorical'\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIRECTORY_LOCATION,\n",
        "    target_size = TARGET_SIZE,\n",
        "    batch_size = 128,\n",
        "    class_mode = CLASS_MODE\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    VAL_DIRECTORY_LOCATION,\n",
        "    target_size = TARGET_SIZE,\n",
        "    batch_size = 128,\n",
        "    class_mode = CLASS_MODE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjpkGy4RtNwJ"
      },
      "source": [
        "Now its your turn to define a model to learn this data.\n",
        "\n",
        "*A hint: Like with the CIFAR-10 assignment, your model may want to learn some high level features and then classify them. This time it may help to make the model a little wider at times.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vrJt6YSDcqjX",
        "outputId": "22f4d7e2-1e87-4b11-d49e-0a6e6f05ab53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 111, 111, 16)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 52, 52, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 12, 12, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 18432)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               9437696   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9536675 (36.38 MB)\n",
            "Trainable params: 9536675 (36.38 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "# Find the features with Convolutions and Pooling\n",
        "   tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "   tf.keras.layers.MaxPooling2D(2, 2),\n",
        "   tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "   tf.keras.layers.MaxPooling2D(2,2),\n",
        "   tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "   tf.keras.layers.MaxPooling2D(2,2),\n",
        "   tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "   tf.keras.layers.MaxPooling2D(2,2),\n",
        "   # Flatten the results to feed into a DNN\n",
        "   tf.keras.layers.Flatten(),\n",
        "   # 512 neuron hidden layer\n",
        "   tf.keras.layers.Dense(512, activation='relu'),\n",
        "   tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# This will print a summary of your model when you're done!\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6UOV_PztNwK"
      },
      "source": [
        "Then you'll need to pick an appropriate loss function and optimizer.\n",
        "\n",
        "*A hint: remember we are classifying again.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nST6CyvCcy-2"
      },
      "outputs": [],
      "source": [
        "OPTIMIZER = 'adam'\n",
        "LOSS_FUNCTION = 'categorical_crossentropy'\n",
        "\n",
        "model.compile(\n",
        "    loss = LOSS_FUNCTION,\n",
        "    optimizer = OPTIMIZER,\n",
        "    metrics = ['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EDyhXfgtNwL"
      },
      "source": [
        "Finally select the number of epochs you'd like to train for and train your model!\n",
        "\n",
        "*A hint: something in the low tens is a good place to start*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3iK9LX9deu2",
        "outputId": "69443131-fc4a-4046-d095-4473f209ac99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7/9 [======================>.......] - ETA: 1s - loss: 1.2621 - accuracy: 0.3239"
          ]
        }
      ],
      "source": [
        "NUM_EPOCHS = 10 #YOUR CODE HERE#\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      epochs = NUM_EPOCHS,\n",
        "      verbose = 1,\n",
        "      validation_data = validation_generator)\n",
        "\n",
        "# summarize history for accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.xlim([0,NUM_EPOCHS])\n",
        "plt.ylim([0.4,1.0])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2-4-11-Question.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}